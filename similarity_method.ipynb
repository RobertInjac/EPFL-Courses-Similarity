{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Similarity Method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we will create a method for __quantifying similarity between two EPFL courses__. \n",
    "\n",
    "We have 3 datasets contaning some data for each EPFL course such as name, description, summary, etc. Using word embeddings, we will create a method which will take that data for a pair of courses and __establish whether they are similar or not.__ There is a small dataset of ground truth (list of pairs of courses for which professors said are similar) which we will use to evaluate the efficiency of our method.\n",
    "\n",
    "The notebook is divided into three parts:\n",
    "1. __Pre-processing:__ Data cleaning, fixing inconsistencies, pre-processing pipeline, creating final dataframe. \n",
    "2. __Method:__ Explanation and implementation of a word-embeddings based similarity method.\n",
    "3. __Evaluation:__ Using our ground-truth to evaluate the efficiency of our similarity method.\n",
    "\n",
    "__Note:__ In this notebook, we will use terms similar courses and related courses synonymously, since we assume that the notion of course \"similarity\" is the same as course \"relatedness\". "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/rinjac/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/rinjac/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%matplotlib notebook\n",
    "\n",
    "# general\n",
    "import re, itertools\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string\n",
    "\n",
    "#sklearn\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "#gensim\n",
    "import gensim\n",
    "from gensim.models import Doc2Vec\n",
    "from gensim.models import KeyedVectors\n",
    "from gensim.models.doc2vec import TaggedDocument\n",
    "\n",
    "#nltk\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 1 Data cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Firstly, let's get the datasets. We have three datasets, which are:\n",
    "1. __course_dependencies__ - Contains ground truth (__some EPFL courses__ for which professors said are similar)\n",
    "2. __course_descriptions__ - Contains course name, description, summary, and other data for __all EPFL courses__\n",
    "3. __course_keywords__ - Contains keywords for each EPFL course (Keywords are usually main concepts taught in the course)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cddf = pd.read_csv('datasets/course_dependencies.csv', index_col=0, keep_default_na=False)\n",
    "tdf = pd.read_csv('datasets/course_desc.csv', index_col=0, keep_default_na=False)\n",
    "kwdf = pd.read_csv('datasets/course_keywords.csv', index_col=0, keep_default_na=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fixing minor inconsistencies in the datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in a lof of database rows, we don't have the course title in English ('CourseNameEN')\n",
    "# but the 'CourseNameFR' field is actually title in English\n",
    "# so we fix this\n",
    "cddf['CourseName1'] = cddf.apply(lambda row: row['CourseNameFR1'] if not row['CourseNameEN1'] else row['CourseNameEN1'], axis=1)\n",
    "cddf['CourseName2'] = cddf.apply(lambda row: row['CourseNameFR2'] if not row['CourseNameEN2'] else row['CourseNameEN2'], axis=1)\n",
    "tdf['CourseName'] = tdf.apply(lambda row: row['CourseNameFR'] if not row['CourseNameEN'] else row['CourseNameEN'], axis=1)\n",
    "\n",
    "# we drop the not needed rows\n",
    "cddf = cddf.drop(columns=['CourseNameEN1', 'CourseNameEN2', 'CourseNameFR1', 'CourseNameFR2'])\n",
    "tdf = tdf.drop(columns=['CourseNameEN', 'CourseNameFR'])\n",
    "\n",
    "# if the course name is still null, we put it as empty string\n",
    "cddf['CourseName1'] = cddf['CourseName1'].apply(lambda x: \" \" if not x else x)\n",
    "cddf['CourseName2'] = cddf['CourseName2'].apply(lambda x: \" \" if not x else x)\n",
    "tdf['CourseName'] = tdf['CourseName'].apply(lambda x: \" \" if not x else x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each course we have the following data:\n",
    "1. __course name__: Name of the course.\n",
    "2. __course description__: Around 50-100 words, description about what is the course about.\n",
    "3. __course summary__: Summary of the curriculum of the course. \n",
    "4. __course keywords__: Important concepts learned in the course.\n",
    "\n",
    "__We will use data obtained from all 4 in our method__. So, for each course we make a \"course_content\" field which will just be all 4 of that, concatenated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concat the course content and summary\n",
    "tdf['CourseContent'] = tdf['CourseContent'] + tdf['SummaryEN']\n",
    "tdf = tdf.drop(columns=['SummaryEN'])\n",
    "\n",
    "cddf['CourseContent1'] = cddf['CourseContent1'] + cddf['SummaryEN1']\n",
    "cddf['CourseContent2'] = cddf['CourseContent2'] + cddf['SummaryEN2']\n",
    "cddf = cddf.drop(columns=['SummaryEN1', 'SummaryEN2'])\n",
    "\n",
    "# remove rows which still have null values\n",
    "cddf = cddf.dropna()\n",
    "tdf = tdf.dropna()\n",
    "\n",
    "# group keywords by course code\n",
    "kwdf = kwdf.groupby('CourseCode')['TagValue'].agg(lambda col: ' '.join(col))\n",
    "kwdf = pd.DataFrame(kwdf)\n",
    "\n",
    "# add keywords for TDF dataframe\n",
    "tdf = tdf.set_index(keys=['CourseCode'], drop=True)\n",
    "tdf = tdf.merge(kwdf, on=['CourseCode'])\n",
    "tdf = tdf.reset_index()\n",
    "\n",
    "# add keywords to the first course\n",
    "cddf = cddf.rename(columns={'CourseCode1': 'CourseCode'})\n",
    "cddf = cddf.set_index(keys=['CourseCode'], drop=True)\n",
    "cddf = cddf.merge(kwdf, on=['CourseCode'])\n",
    "cddf = cddf.reset_index()\n",
    "cddf = cddf.rename(columns={'CourseCode': 'CourseCode1', 'TagValue': 'TagValue1'})\n",
    "\n",
    "# add keywords to the second course\n",
    "cddf = cddf.rename(columns={'CourseCode2': 'CourseCode'})\n",
    "cddf = cddf.set_index(keys=['CourseCode'], drop=True)\n",
    "cddf = cddf.merge(kwdf, on=['CourseCode'])\n",
    "cddf = cddf.reset_index()\n",
    "cddf = cddf.rename(columns={'CourseCode': 'CourseCode2', 'TagValue': 'TagValue2'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining pre-processing functions we are going to use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_nonascii(s):\n",
    "    return s.encode('ascii', 'ignore').decode(\"utf-8\")\n",
    "\n",
    "def remove_newline(s):\n",
    "    return s.replace('\\n','')\n",
    "\n",
    "def remove_squote(s):\n",
    "    return s.replace('<squote/>',' ')\n",
    "\n",
    "stop_words = stopwords.words('english')\n",
    "def remove_stop_words(tokens):\n",
    "    return [word for word in tokens if word not in stop_words]\n",
    "\n",
    "french_stop_words = stopwords.words('french')\n",
    "def remove_french_stop_words(tokens):\n",
    "    return [word for word in tokens if word not in french_stop_words]\n",
    "\n",
    "punc = list(string.punctuation)\n",
    "def remove_punc(tokens):\n",
    "    return [word for word in tokens if word not in punc]\n",
    "\n",
    "def to_lower(tokens):\n",
    "    return [token.lower() for token in tokens]\n",
    "\n",
    "def apply_preproc(df, column, func): \n",
    "    df[column] = df[column].apply(func)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Finding most common words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__For reasons explained below (in the section 2.2)__ we will write the code which finds the N most common words in course descriptions and a pre-processing function which will remove them. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ndf = tdf.copy()\n",
    "\n",
    "str_list = []\n",
    "for i in range(len(tdf)):\n",
    "    str_list.append(tdf.iloc[i]['CourseContent'])\n",
    "all_content = ''.join(str_list)\n",
    "                    \n",
    "all_content = word_tokenize(all_content)\n",
    "all_content = to_lower(all_content)\n",
    "all_content = remove_stop_words(all_content)\n",
    "all_content = remove_punc(all_content)\n",
    "\n",
    "freq_d = dict()\n",
    "for w in all_content:\n",
    "    freq_d[w] = 1 + freq_d.get(w, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq = [(freq_d[key], key) for key in freq_d]\n",
    "freq.sort()\n",
    "freq.reverse()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['course', 'semicolon/', 'students', 'design', 'systems', 'analysis', 'methods', 'introduction', 'squote/', 'basic', 'models', 'techniques', 'energy', 'project', 'theory', 'concepts', '2', 'applications', 'materials', 'data', 'research', '3', 'different', 'processes', 'principles', 'system', 'tools', 'student', 'development', 'work', 'well', 'engineering', 'field', 'linear', 'topics', 'management', 'properties', 'part', 'also', 'control', '4', 'use', 'main', 'understanding', 'practical', 'learning', 'social', 'knowledge', 'using', 'study', 'understand', 'modeling', 'theoretical', 'problems', 'examples', 'various', 'structure', 'aspects', 'digital', 'science', '5', 'process', 'urban', 'fundamental', 'based', '1', 'application', 'new', \"''\", 'specific', 'used', 'processing', 'issues', 'information', 'time', 'approach', 'power', 'model', 'structures', 'learn', 'physical', 'chemical', '``', 'studies', 'case', 'technology', 'related', 'general', 'types', 'optical', 'quantum', 'physics', 'including', 'equations', 'environmental', 'class', '6', 'algorithms', 'modern', 'architecture']\n"
     ]
    }
   ],
   "source": [
    "most_common_f = freq[:100]\n",
    "_, most_common = [list(tup) for tup in zip(*most_common_f)]\n",
    "print(most_common)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_most_common_words(tokens):\n",
    "    return [word for word in tokens if word not in most_common]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Creating final dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need two types of course-pairs: \n",
    "1. the courses which are similar\n",
    "2. the courses which are not similar\n",
    "\n",
    "We have 1. from the dataset course_dependencies (the ground truth). To make 2., we are going to randomly select some course pairs from all of the courses, as long as they are not in the \"similar course-pairs list\" which is defined by 1.\n",
    "\n",
    "After we get two dataframes (one for course-pairs which are similar and one for ones which are not) we will merge them into a single dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take a random sample of the course descriptions table (used for making pairs of not-similar samples)\n",
    "tdf1 = tdf.sample(n = 250)\n",
    "tdf2 = tdf.sample(n = 250)\n",
    "tdf1 = tdf1.rename(index=str, columns={\"CourseCode\": \"CourseCode1\", \"CourseName\": \"CourseName1\", \"CourseContent\": \"CourseContent1\", \"TagValue\": \"TagValue1\"})\n",
    "tdf2 = tdf2.rename(index=str, columns={\"CourseCode\": \"CourseCode2\", \"CourseName\": \"CourseName2\", \"CourseContent\": \"CourseContent2\", \"TagValue\": \"TagValue2\"})\n",
    "tdf1 = tdf1.reset_index(drop=True)\n",
    "tdf2 = tdf2.reset_index(drop=True)\n",
    "\n",
    "# create the table of samples which are not-similar \n",
    "tdf = pd.concat([tdf1, tdf2], axis = 1)\n",
    "tdf.insert(2, 'Relationship', 'None')\n",
    "tdf = tdf.drop_duplicates(subset=['CourseCode1', 'CourseCode2'], keep='first')\n",
    "tdf = tdf.query(\"CourseCode1 != CourseCode2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge the similar and not-similar samples into a single table \n",
    "cddf = pd.concat([cddf, tdf], axis=0, sort=False)\n",
    "cddf = cddf.reset_index(drop=True)\n",
    "\n",
    "# remove duplicates\n",
    "# (since the sampling is random, it could happen that a pair of courses is both similar and not-similar\n",
    "# we keep just the similar version of these pairs, since that is the ground truth)\n",
    "cddf = cddf.drop_duplicates(subset=['CourseCode1', 'CourseCode2'], keep='first')\n",
    "\n",
    "# shuffle\n",
    "cddf = cddf.sample(frac = 1)\n",
    "cddf = cddf.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have one dataframe for all course-pairs (both similar and not-similar) we will perform pre-processing on it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['CourseContent1', 'CourseName1', 'CourseContent2', 'CourseName2', 'TagValue1', 'TagValue2']\n",
    "\n",
    "for column in columns:\n",
    "    # tokenization\n",
    "    apply_preproc(cddf, column, word_tokenize)\n",
    "    # to lower\n",
    "    apply_preproc(cddf, column, to_lower)\n",
    "    # remove stop words\n",
    "    apply_preproc(cddf, column, remove_stop_words)\n",
    "    # remove french stop words\n",
    "    apply_preproc(cddf, column, remove_french_stop_words)\n",
    "    # remove punc\n",
    "    apply_preproc(cddf, column, remove_punc)\n",
    "\n",
    "# remove most common words\n",
    "# ONLY for the course content\n",
    "apply_preproc(cddf, 'CourseContent1', remove_most_common_words)\n",
    "apply_preproc(cddf, 'CourseContent2', remove_most_common_words)\n",
    "\n",
    "# merge content and keywords\n",
    "cddf['CourseContent1'] = cddf['TagValue1'] + cddf['CourseContent1']\n",
    "cddf['CourseContent2'] = cddf['TagValue2'] + cddf['CourseContent2']\n",
    "cddf = cddf.drop(columns=['TagValue1', 'TagValue2'])\n",
    "\n",
    "# merge name and content\n",
    "cddf['CourseContent1'] = cddf['CourseName1'] + cddf['CourseContent1']\n",
    "cddf['CourseContent2'] = cddf['CourseName2'] + cddf['CourseContent2']\n",
    "cddf = cddf.drop(columns=['CourseName1', 'CourseName2'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check out how our pre-processed dataframe looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CourseCode2</th>\n",
       "      <th>CourseCode1</th>\n",
       "      <th>CourseContent1</th>\n",
       "      <th>Relationship</th>\n",
       "      <th>CourseContent2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ME-473</td>\n",
       "      <td>EE-704</td>\n",
       "      <td>[computational, perception, using, multimodal,...</td>\n",
       "      <td>None</td>\n",
       "      <td>[computational, solid, structural, dynamics, d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MICRO-420</td>\n",
       "      <td>MICRO-424</td>\n",
       "      <td>[optics, laboratories, ii, waveguide, fiber, o...</td>\n",
       "      <td>Depends on</td>\n",
       "      <td>[selected, topics, advanced, optics, optics, c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CS-101</td>\n",
       "      <td>CS-251</td>\n",
       "      <td>[theory, computation, théorie, complexité, np-...</td>\n",
       "      <td>Depends on</td>\n",
       "      <td>[advanced, information, computation, communica...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MICRO-330</td>\n",
       "      <td>ME-402</td>\n",
       "      <td>[mechanical, engineering, project, ii, communi...</td>\n",
       "      <td>None</td>\n",
       "      <td>[sensors, capteurs, sensors, sensors, characte...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CS-322</td>\n",
       "      <td>CS-449</td>\n",
       "      <td>[systems, data, science, databases, data-paral...</td>\n",
       "      <td>Depends on</td>\n",
       "      <td>[introduction, database, systems, database, ma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>HUM-365</td>\n",
       "      <td>HUM-436(a)</td>\n",
       "      <td>[sciences, religions, naturalisme, scientifiqu...</td>\n",
       "      <td>Benefits from</td>\n",
       "      <td>[sciences, religions, b, créationnismes, evolu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>MICRO-523</td>\n",
       "      <td>MICRO-423</td>\n",
       "      <td>[optics, laboratories, he-ne, laser, optical, ...</td>\n",
       "      <td>Benefits from</td>\n",
       "      <td>[optical, detectors, caméras, cmos, photodiode...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>COM-401</td>\n",
       "      <td>MATH-409</td>\n",
       "      <td>[algebraic, curves, cryptography, discrete, lo...</td>\n",
       "      <td>Benefits from</td>\n",
       "      <td>[cryptography, security, cryptography, secure,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>HUM-245(a)</td>\n",
       "      <td>MGT-403</td>\n",
       "      <td>[economics, innovation, biomedical, industry, ...</td>\n",
       "      <td>None</td>\n",
       "      <td>[economy, innovation, innovation, micro-économ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>MSE-632</td>\n",
       "      <td>CIVIL-604</td>\n",
       "      <td>[introduction, digital, signal, processing, us...</td>\n",
       "      <td>None</td>\n",
       "      <td>[ccmx, winter, school, nanoparticles, fundamen...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  CourseCode2 CourseCode1                                     CourseContent1  \\\n",
       "0      ME-473      EE-704  [computational, perception, using, multimodal,...   \n",
       "1   MICRO-420   MICRO-424  [optics, laboratories, ii, waveguide, fiber, o...   \n",
       "2      CS-101      CS-251  [theory, computation, théorie, complexité, np-...   \n",
       "3   MICRO-330      ME-402  [mechanical, engineering, project, ii, communi...   \n",
       "4      CS-322      CS-449  [systems, data, science, databases, data-paral...   \n",
       "5     HUM-365  HUM-436(a)  [sciences, religions, naturalisme, scientifiqu...   \n",
       "6   MICRO-523   MICRO-423  [optics, laboratories, he-ne, laser, optical, ...   \n",
       "7     COM-401    MATH-409  [algebraic, curves, cryptography, discrete, lo...   \n",
       "8  HUM-245(a)     MGT-403  [economics, innovation, biomedical, industry, ...   \n",
       "9     MSE-632   CIVIL-604  [introduction, digital, signal, processing, us...   \n",
       "\n",
       "    Relationship                                     CourseContent2  \n",
       "0           None  [computational, solid, structural, dynamics, d...  \n",
       "1     Depends on  [selected, topics, advanced, optics, optics, c...  \n",
       "2     Depends on  [advanced, information, computation, communica...  \n",
       "3           None  [sensors, capteurs, sensors, sensors, characte...  \n",
       "4     Depends on  [introduction, database, systems, database, ma...  \n",
       "5  Benefits from  [sciences, religions, b, créationnismes, evolu...  \n",
       "6  Benefits from  [optical, detectors, caméras, cmos, photodiode...  \n",
       "7  Benefits from  [cryptography, security, cryptography, secure,...  \n",
       "8           None  [economy, innovation, innovation, micro-économ...  \n",
       "9           None  [ccmx, winter, school, nanoparticles, fundamen...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cddf.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "422\n"
     ]
    }
   ],
   "source": [
    "print(len(cddf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__As we can see, we have 422 course pairs, of which around half are similar and half are not.__ For each course of the pair we have a course code and course content."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section we will describe and create our similarity method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Word embeddings method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our method uses word embeddings. The word embeddings we chose are _fasttext_ word2vec embeddings: 1 million word vectors trained on Wikipedia 2017, UMBC webbase corpus and statmt.org news dataset (16B tokens). It's possible to download them [here](https://fasttext.cc/docs/en/english-vectors.html) (download _wiki-news-300d-1M.vec.zip_)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pretrained word2vec on wikipedia\n",
    "model = KeyedVectors.load_word2vec_format('wiki-news-300d-1M.vec')\n",
    "EMBEDDING_SIZE = 300"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our similarity method is simple. __To establish similarity between two courses, we project both courses into vector space and find the cosine similarity between them.__\n",
    "\n",
    "To project the course into a vector space, we are using word embeddings. We have a list of 200 to 1000 words related to the course for each course (the column course_content). We get the word2vec word embeddings vector for each word. Then we take the average of the word embeddings for words in course_content, and that is the embedding of the course in vector space.\n",
    "\n",
    "__Why we think this will work?__ If two words are semantically similar, their word embedding vectors should be close to each other in the vector space. The words in the course_content list should mostly be related to the course. If the take the \"course embedding\" for each course (which is calculated from that list of words), it should be that similar courses are near to each other in vector space: most of their words in course_content list should be semantically similar.\n",
    "\n",
    "Now, let's define a function which calculates the average word embeddings from a list of words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_average_vector(words_list):\n",
    "    \"\"\" Function for getting the average word embedding out of list of words \"\"\"\n",
    "    \n",
    "    base = np.zeros(EMBEDDING_SIZE)\n",
    "    word_vec = 0\n",
    "    n = 0\n",
    "    for word in words_list:\n",
    "        try:\n",
    "            word_vec = model[word]\n",
    "            n += 1\n",
    "        except KeyError:\n",
    "            word_vec = np.zeros(300)\n",
    "        base = np.add(base, word_vec)\n",
    "    base = np.divide(base, n)\n",
    "    \n",
    "    return base.reshape(1, -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also, we are going to define a function which returnes cosine similarity between two lists of words, using the above function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_similarity(words1, words2):\n",
    "    base1 = get_average_vector(words1)\n",
    "    base2 = get_average_vector(words2)\n",
    "    sim = cosine_similarity(base1, base2)\n",
    "    return sim[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Explanation of most common word removal "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the pre-processing step, we removed top 100 most common words from our course_content column. Why did we do this?\n",
    "\n",
    "We want each course_content list to have as much as possible words related to the course, and the least possible amount of words which are not related to the course. Considering a lot of words are related to all courses (such as \"course\", \"project\", \"theory\", etc), these words genereally increase our similarity scores by making all courses more similar to each other, because they all share those words. And even worse, if some course has a smaller proportion of these common words, it will seem less related to other courses just because of that. So we fix this by removing the top 100 most common words found in all courses.\n",
    "\n",
    "Does this actually help? Let's have a small example.\n",
    "\n",
    "We have two related and unrelated courses, and the course_content word list for them without the top 100 most common words removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unrelated similarity is 0.8689054222463344\n",
      "Related similarity is 0.9740207131280505\n",
      "Difference in similarity is 0.10511529088171612\n"
     ]
    }
   ],
   "source": [
    "# data from two not related courses (CIVIL-552 and EE-201)\n",
    "unrelated1 = ['Introduction', 'Conceptual', 'seismic', 'design', 'Analysis', 'methods', 'Design', 'evaluation', 'methods', 'Design', 'philosophies', 'Reinforced', 'concrete', 'structures', 'Existing', 'reinforced', 'concrete', 'masonry', 'structuresThis', 'course', 'deals', 'main', 'aspects', 'seismic', 'design', 'buildings', 'bridges', 'It', 'covers', 'different', 'structural', 'design', 'evaluation', 'philosophies', 'new', 'existing', 'reinforced', 'concrete', 'masonry', 'structures']\n",
    "unrelated2 = ['See', 'French', 'textThis', 'course', 'deals', 'electromagnetism', 'free', 'space', 'continuous', 'media', 'Starting', 'basic', 'principles', 'establish', 'methods', 'solving', 'Maxwell', 'squote/', 'equation', 'vacuum', 'complex', 'material', 'media']\n",
    "\n",
    "# data from two related courses (CS-328 and CS-440)\n",
    "related1 = ['This', 'course', 'provides', 'first', 'introduction', 'field', 'numerical', 'analysis', 'strong', 'focus', 'visual', 'computing', 'applications', 'Using', 'examples', 'computer', 'graphics', 'geometry', 'processing', 'computer', 'vision', 'computational', 'photography', 'students', 'gain', 'hands-on', 'experience', 'range', 'essential', 'numerical', 'algorithms', 'The', 'course', 'begin', 'review', 'important', 'considerations', 'regarding', 'floating', 'point', 'arithmetic', 'error', 'propagation', 'numerical', 'computations', 'Following', 'students', 'study', 'experiment', 'several', 'techniques', 'solve', 'systems', 'linear', 'non-linear', 'equations', 'Since', 'many', 'interesting', 'problems', 'solved', 'exactly', 'numerical', 'optimization', 'techniques', 'constitute', 'second', 'major', 'topic', 'course', 'Students', 'learn', 'principal', 'component', 'analysis', 'leveraged', 'compress', 'reduce', 'dimension', 'large', 'datasets', 'make', 'easier', 'store', 'analyze', 'The', 'course', 'concludes', 'review', 'numerical', 'methods', 'make', 'judicious', 'use', 'randomness', 'solve', 'problems', 'would', 'otherwise', 'intractable', 'Students', 'opportunity', 'gain', 'practical', 'experience', 'discussed', 'methods', 'using', 'programming', 'assignments', 'based', 'Scientific', 'Python']\n",
    "related2 = ['This', 'project-based', 'course', 'students', 'initially', 'receive', 'basic', 'software', 'package', 'lacks', 'rendering-related', 'functionality', 'Over', 'course', 'semester', 'discuss', 'variety', 'concepts', 'tools', 'including', 'basic', 'physical', 'quantities', 'light', 'interacts', 'surfaces', 'solve', 'resulting', 'mathematical', 'problem', 'numerically', 'create', 'realistic', 'images', 'Advanced', 'topics', 'include', 'participating', 'media', 'material', 'models', 'sub-surface', 'light', 'transport', 'Markov', 'Chain', 'Monte', 'Carlo', 'Methods', 'Each', 'major', 'topic', 'accompanied', 'assignment', 'students', 'implement', 'solution', 'algorithms', 'obtain', 'practical', 'experience', 'techniques', 'within', 'software', 'framework', 'Towards', 'end', 'course', 'students', 'realize', 'self-directed', 'final', 'project', 'extends', 'rendering', 'software', 'additional', 'features', 'choosing', 'The', 'objective', 'final', 'project', 'create', 'single', 'image', 'technical', 'artistic', 'merit', 'entered', 'rendering', 'competition', 'judged', 'independent', 'panel', 'computer', 'graphics', 'experts']\n",
    "\n",
    "# calculate similarity for unrelated\n",
    "sim1 = get_similarity(unrelated1, unrelated2)\n",
    "print(\"Unrelated similarity is \" + str(sim1))\n",
    "\n",
    "# calculate similarity for related\n",
    "sim2 = get_similarity(related1, related2)\n",
    "print(\"Related similarity is \" + str(sim2))\n",
    "\n",
    "print(\"Difference in similarity is \" + str(sim2 - sim1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Now, we will see how do the similarity scores change when we remove the top 100 most common words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unrelated similarity is 0.8056721208269843\n",
      "Related similarity is 0.9634055755047493\n",
      "Difference in similarity is 0.157733454677765\n"
     ]
    }
   ],
   "source": [
    "unrelated1 = remove_most_common_words(unrelated1)\n",
    "unrelated2 = remove_most_common_words(unrelated2)\n",
    "related1 = remove_most_common_words(related1)\n",
    "related2 = remove_most_common_words(related2)\n",
    "\n",
    "# calculate similarity for unrelated\n",
    "sim1 = get_similarity(unrelated1, unrelated2)\n",
    "print(\"Unrelated similarity is \" + str(sim1))\n",
    "\n",
    "# calculate similarity for related\n",
    "sim2 = get_similarity(related1, related2)\n",
    "print(\"Related similarity is \" + str(sim2))\n",
    "\n",
    "print(\"Difference in similarity is \" + str(sim2 - sim1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, we managed to increase the difference to 0.15. This is just a small example, but it does give credit to the idea that we should remove the top 100 most common words.\n",
    "\n",
    "Finally, we will have a human pick the words which seem most relevant to the course from the course_content list (before top 100 most common removal). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unrelated similarity is 0.7204567820856593\n",
      "Related similarity is 0.9433678431101818\n",
      "Difference in similarity is 0.22291106102452252\n"
     ]
    }
   ],
   "source": [
    "unrelated1_ = ['Conceptual', 'seismic', 'design', 'philosophies', 'concrete', 'structures', 'reinforced', 'masonry', 'seismic', 'design', 'buildings', 'bridges', 'structural', 'design', 'reinforced', 'masonry', 'structures']\n",
    "unrelated2_ = ['electromagnetism', 'free', 'space', 'continuous', 'solving', 'Maxwell', 'equation', 'vacuum', 'complex', 'material']\n",
    "\n",
    "related1_ = ['numerical', 'analysis', 'visual', 'computing', 'computer', 'graphics', 'geometry', 'processing', 'computer', 'vision', 'computational', 'photography', 'numerical', 'algorithms', 'floating', 'point', 'arithmetic', 'error', 'propagation', 'numerical', 'computations', 'experiment', 'techniques', 'solve', 'systems', 'linear', 'non-linear', 'equations', 'numerical', 'optimization', 'techniques', 'leveraged', 'compress', 'reduce', 'dimension', 'large', 'datasets', 'store', 'analyze', 'numerical', 'methods', 'randomness', 'solve', 'problems', 'Scientific', 'Python']\n",
    "related2_ = ['project-based', 'software', 'package', 'rendering-related', 'physical', 'quantities', 'light', 'interacts', 'surfaces', 'mathematical', 'problem', 'numerically', 'create', 'realistic', 'images', 'models', 'sub-surface', 'Markov', 'Chain', 'Monte', 'Carlo', 'implement', 'solution', 'algorithms', 'practical', 'experience', 'software', 'framework', 'self-directed', 'rendering', 'software', 'features', 'project', 'computer', 'graphics',]\n",
    "\n",
    "# calculate similarity for unrelated\n",
    "sim1 = get_similarity(unrelated1_, unrelated2_)\n",
    "print(\"Unrelated similarity is \" + str(sim1))\n",
    "\n",
    "# calculate similarity for related\n",
    "sim2 = get_similarity(related1_, related2_)\n",
    "print(\"Related similarity is \" + str(sim2))\n",
    "\n",
    "print(\"Difference in similarity is \" + str(sim2 - sim1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The human managed to have the difference at 0.22, so there is possibly room for improvement. However, the removal of top 100 words seems to help our method, so we will keep it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have our method, we have to evaluate it. We have the ground truth (we know which courses truly are similar to each other), so we will compare our method's results with those.\n",
    "\n",
    "In the previous chapter, we established a method for measuring the similarity of two courses. But this method gives us a continuous value between 0 and 1 - and we want to have a discrete value: related or not related. We need one hyperparameter: threshold. If the similarity is above the threshold, the courses are related, and if it is below, they are not.\n",
    "\n",
    "To calculate the best threshold we will use cross-validation. We will split the dataset: 70% for the train set and 30% for the test set. We will find the best value for our hyperparamater, the threshold, on the test set. It will be the threshold for which the F-score is the highest. Then, we will evaluate our method on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data in train and test set\n",
    "train = cddf.sample(frac=0.7)\n",
    "test = cddf.drop(train.index)\n",
    "\n",
    "train = train.reset_index()\n",
    "test = test.reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will use the train set to find the threshold value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# similarity threshold will be between 0 and 1 \n",
    "thresholds = np.linspace(0, 1, num=101)\n",
    "\n",
    "best_f1_score = 0\n",
    "best_threshold = 0\n",
    "\n",
    "# for EVERY value of threshold we can have\n",
    "# on the train set\n",
    "# calculate cosine similarity between courses descriptions using word2vec\n",
    "# take word embedding of each word in text, then find their average\n",
    "for threshold in thresholds:\n",
    "    \n",
    "    t_p = 0\n",
    "    t_n = 0\n",
    "    f_p = 0\n",
    "    f_n = 0\n",
    "    \n",
    "    for k in range(len(train)):\n",
    "        list1 = train.iloc[k]['CourseContent1']\n",
    "        list2 = train.iloc[k]['CourseContent2']\n",
    "\n",
    "        sim = get_similarity(list1, list2)\n",
    "\n",
    "        if sim>=threshold:\n",
    "            if train.iloc[k]['Relationship']!='None':\n",
    "                t_p += 1\n",
    "            else:\n",
    "                f_p += 1\n",
    "        else:\n",
    "            if train.iloc[k]['Relationship']!='None':\n",
    "                f_n += 1\n",
    "            else:\n",
    "                t_n += 1\n",
    "    \n",
    "    precision = 0\n",
    "    recall = 0\n",
    "    f1_score = 0\n",
    "    if t_p + f_p != 0:\n",
    "        precision = t_p / (t_p + f_p)\n",
    "    if t_p + f_n != 0:\n",
    "        recall = t_p / (t_p + f_n)\n",
    "    if precision + recall != 0:\n",
    "        f1_score = (2 * (precision * recall)) / (precision + recall)\n",
    "    \n",
    "    if f1_score > best_f1_score:\n",
    "        best_f1_score = f1_score\n",
    "        best_threshold = threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.89\n"
     ]
    }
   ],
   "source": [
    "THRESHOLD = best_threshold\n",
    "print(THRESHOLD)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have threshold value, we can evaluate our method on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_eval(t_p, t_n, f_p, f_n):\n",
    "    accuracy = (t_p + t_n) / (t_p + t_n + f_p + f_n)\n",
    "    precision = t_p / (t_p + f_p)\n",
    "    recall = t_p / (t_p + f_n)\n",
    "    f1_score = (2 * (precision * recall)) / (precision + recall)\n",
    "\n",
    "    print(str(t_p) + \" | \" + str(f_p))\n",
    "    print(str(f_n) + \" | \" + str(t_n))\n",
    "\n",
    "    print(\"Accuracy: \" + str(accuracy))\n",
    "    print(\"Precision: \" + str(precision))\n",
    "    print(\"Recall: \" + str(recall))\n",
    "    print(\"################\")\n",
    "    print(\"F1-score: \" + str(f1_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42 | 12\n",
      "11 | 62\n",
      "Accuracy: 0.8188976377952756\n",
      "Precision: 0.7777777777777778\n",
      "Recall: 0.7924528301886793\n",
      "################\n",
      "F1-score: 0.7850467289719626\n"
     ]
    }
   ],
   "source": [
    "t_p = 0\n",
    "t_n = 0\n",
    "f_p = 0\n",
    "f_n = 0\n",
    "\n",
    "f_ns = []\n",
    "f_ps = []\n",
    "\n",
    "# calculate cosine similarity between courses descriptions using word2vec\n",
    "# take word embedding of each word in text, then find their average\n",
    "for k in range(len(test)):\n",
    "    list1 = test.iloc[k]['CourseContent1']\n",
    "    list2 = test.iloc[k]['CourseContent2']\n",
    "    \n",
    "    sim = get_similarity(list1, list2)\n",
    "    \n",
    "    if sim>=THRESHOLD:\n",
    "        if test.iloc[k]['Relationship']!='None':\n",
    "            t_p += 1\n",
    "        else:\n",
    "            f_p += 1\n",
    "    else:\n",
    "        if test.iloc[k]['Relationship']!='None':\n",
    "            f_n += 1\n",
    "        else:\n",
    "            t_n += 1\n",
    "    \n",
    "print_eval(t_p, t_n, f_p, f_n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, our method manages to predict whether the two courses are related quite well. \n",
    "\n",
    "The number of false positives is larger than the number of false negatives because the not-related courses in our dataframe might actually be related (we got not-related by just taking courses which are not in the \"related courses\" dataset, but it could be that some courses which are related were not noted by the professors which made the related-courses list.)  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
