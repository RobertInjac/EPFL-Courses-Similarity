{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating a Similarity Method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we will create a method for quantifying similariy between two courses. To check if our method is efficient, there is a small dataset of ground truth (List of pairs of courses for which professors said are similar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/rinjac/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /home/rinjac/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%matplotlib notebook\n",
    "\n",
    "# general\n",
    "import re, itertools\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string\n",
    "\n",
    "#sklearn\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "#gensim\n",
    "import gensim\n",
    "from gensim.models import Doc2Vec\n",
    "from gensim.models import KeyedVectors\n",
    "from gensim.models.doc2vec import TaggedDocument\n",
    "\n",
    "#nltk\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 1 Data cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Firstly, let's get the datasets. We have three datasets, which are:\n",
    "1. __course_dependencies__ - Contains ground truth (__some courses__ for which professors said are similar)\n",
    "2. __course_descriptions__ - Contains course name, description, summary, and other data for __all courses__\n",
    "3. __course_keywords__ - Contains keywords for each course (Keywords are usually main concepts taught in the course)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "cddf = pd.read_csv('datasets/course_dependencies.csv', index_col=0, keep_default_na=False)\n",
    "tdf = pd.read_csv('datasets/course_desc.csv', index_col=0, keep_default_na=False)\n",
    "kwdf = pd.read_csv('datasets/course_keywords.csv', index_col=0, keep_default_na=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fixing minor inconsistencies in the datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in a lof of database rows, we don't have the course title in English ('CourseNameEN')\n",
    "# but the 'CourseNameFR' field is actually title in English\n",
    "# so we fix this\n",
    "cddf['CourseName1'] = cddf.apply(lambda row: row['CourseNameFR1'] if not row['CourseNameEN1'] else row['CourseNameEN1'], axis=1)\n",
    "cddf['CourseName2'] = cddf.apply(lambda row: row['CourseNameFR2'] if not row['CourseNameEN2'] else row['CourseNameEN2'], axis=1)\n",
    "tdf['CourseName'] = tdf.apply(lambda row: row['CourseNameFR'] if not row['CourseNameEN'] else row['CourseNameEN'], axis=1)\n",
    "\n",
    "# we drop the not needed rows\n",
    "cddf = cddf.drop(columns=['CourseNameEN1', 'CourseNameEN2', 'CourseNameFR1', 'CourseNameFR2'])\n",
    "tdf = tdf.drop(columns=['CourseNameEN', 'CourseNameFR'])\n",
    "\n",
    "# if the course name is still null, we put it as empty string\n",
    "cddf['CourseName1'] = cddf['CourseName1'].apply(lambda x: \" \" if not x else x)\n",
    "cddf['CourseName2'] = cddf['CourseName2'].apply(lambda x: \" \" if not x else x)\n",
    "tdf['CourseName'] = tdf['CourseName'].apply(lambda x: \" \" if not x else x)\n",
    "\n",
    "# concat the course content and summary\n",
    "tdf['CourseContent'] = tdf['CourseContent'] + tdf['SummaryEN']\n",
    "tdf = tdf.drop(columns=['SummaryEN'])\n",
    "\n",
    "cddf['CourseContent1'] = cddf['CourseContent1'] + cddf['SummaryEN1']\n",
    "cddf['CourseContent2'] = cddf['CourseContent2'] + cddf['SummaryEN2']\n",
    "cddf = cddf.drop(columns=['SummaryEN1', 'SummaryEN2'])\n",
    "\n",
    "# remove rows which still have null values\n",
    "cddf = cddf.dropna()\n",
    "tdf = tdf.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merging data from keyword dataset to other two datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# group keywords by course code\n",
    "kwdf = kwdf.groupby('CourseCode')['TagValue'].agg(lambda col: ' '.join(col))\n",
    "kwdf = pd.DataFrame(kwdf)\n",
    "\n",
    "# add keywords for TDF dataframe\n",
    "tdf = tdf.set_index(keys=['CourseCode'], drop=True)\n",
    "tdf = tdf.merge(kwdf, on=['CourseCode'])\n",
    "tdf = tdf.reset_index()\n",
    "\n",
    "# add keywords to the first course\n",
    "cddf = cddf.rename(columns={'CourseCode1': 'CourseCode'})\n",
    "cddf = cddf.set_index(keys=['CourseCode'], drop=True)\n",
    "cddf = cddf.merge(kwdf, on=['CourseCode'])\n",
    "cddf = cddf.reset_index()\n",
    "cddf = cddf.rename(columns={'CourseCode': 'CourseCode1', 'TagValue': 'TagValue1'})\n",
    "\n",
    "# add keywords to the second course\n",
    "cddf = cddf.rename(columns={'CourseCode2': 'CourseCode'})\n",
    "cddf = cddf.set_index(keys=['CourseCode'], drop=True)\n",
    "cddf = cddf.merge(kwdf, on=['CourseCode'])\n",
    "cddf = cddf.reset_index()\n",
    "cddf = cddf.rename(columns={'CourseCode': 'CourseCode2', 'TagValue': 'TagValue2'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining pre-processing functions we are going to use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_nonascii(s):\n",
    "    return s.encode('ascii', 'ignore').decode(\"utf-8\")\n",
    "\n",
    "def remove_newline(s):\n",
    "    return s.replace('\\n','')\n",
    "\n",
    "def remove_squote(s):\n",
    "    return s.replace('<squote/>',' ')\n",
    "\n",
    "stop_words = stopwords.words('english')\n",
    "def remove_stop_words(tokens):\n",
    "    return [word for word in tokens if word not in stop_words]\n",
    "\n",
    "french_stop_words = stopwords.words('french')\n",
    "def remove_french_stop_words(tokens):\n",
    "    return [word for word in tokens if word not in french_stop_words]\n",
    "\n",
    "punc = list(string.punctuation)\n",
    "def remove_punc(tokens):\n",
    "    return [word for word in tokens if word not in punc]\n",
    "\n",
    "def to_lower(tokens):\n",
    "    return [token.lower() for token in tokens]\n",
    "\n",
    "def apply_preproc(df, column, func): \n",
    "    df[column] = df[column].apply(func)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Finding most common words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For reasons explained below (in the Example section) we will write the code which finds the N most common words in course descriptions and a pre-processing function which will remove them. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "ndf = tdf.copy()\n",
    "\n",
    "str_list = []\n",
    "for i in range(len(tdf)):\n",
    "    str_list.append(tdf.iloc[i]['CourseContent'])\n",
    "all_content = ''.join(str_list)\n",
    "                    \n",
    "all_content = word_tokenize(all_content)\n",
    "all_content = to_lower(all_content)\n",
    "all_content = remove_stop_words(all_content)\n",
    "all_content = remove_punc(all_content)\n",
    "\n",
    "freq_d = dict()\n",
    "for w in all_content:\n",
    "    freq_d[w] = 1 + freq_d.get(w, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq = [(freq_d[key], key) for key in freq_d]\n",
    "freq.sort()\n",
    "freq.reverse()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['course', 'students', 'semicolon/', 'design', 'analysis', 'squote/', 'methods', 'systems', 'introduction', 'project', 'basic', '2', 'research', 'energy', 'techniques', '3', 'student', 'concepts', 'work', 'development', 'theory', 'materials', 'field', 'models', 'social', 'tools', 'different', 'linear', 'also', 'well', 'applications', 'urban', '4', 'study', 'understand', 'use', 'part', 'new', 'engineering', 'theoretical', 'principles', 'management', 'various', 'knowledge', 'using', 'data', 'system', '5', 'approach', 'properties', '1', 'structures', 'main', 'practical', 'process', 'understanding', 'science', \"''\", 'topics', 'fundamental', '``', 'specific', 'learning', 'issues', 'processes', 'elements', 'structure', 'model', 'microscopy', 'application', '--', 'electron', 'control', 'aspects', 'power', 'teaching', 'physics', 'one', 'examples', 'time', 'technology', 'related', 'first', 'architecture', '6', 'scientific', 'information', 'studies', 'semester', 'types', 'modeling', 'construction', 'concrete', 'used', 'following', 'climate', 'problems', 'economic', 'public', 'case']\n"
     ]
    }
   ],
   "source": [
    "most_common_f = freq[:100]\n",
    "_, most_common = [list(tup) for tup in zip(*most_common_f)]\n",
    "print(most_common)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_most_common_words(tokens):\n",
    "    return [word for word in tokens if word not in most_common]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Final pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need two types of course-pairs: \n",
    "1. the courses which are similar\n",
    "2. the courses which are not similar\n",
    "\n",
    "We have 1. from the dataset course_dependencies (the ground truth). To make 2., we are going to randomly select some course pairs from all of the courses, as long as they are not in the \"similar course-pairs list\" which is defined by 1.\n",
    "\n",
    "After we get two dataframes (one for course-pairs which are similar and one for ones which are not) we will merge them into a single dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take a random sample of the course descriptions table (used for making not-similar samples)\n",
    "tdf1 = tdf.sample(n = 250)\n",
    "tdf2 = tdf.sample(n = 250)\n",
    "tdf1 = tdf1.rename(index=str, columns={\"CourseCode\": \"CourseCode1\", \"CourseName\": \"CourseName1\", \"CourseContent\": \"CourseContent1\", \"TagValue\": \"TagValue1\"})\n",
    "tdf2 = tdf2.rename(index=str, columns={\"CourseCode\": \"CourseCode2\", \"CourseName\": \"CourseName2\", \"CourseContent\": \"CourseContent2\", \"TagValue\": \"TagValue2\"})\n",
    "tdf1 = tdf1.reset_index(drop=True)\n",
    "tdf2 = tdf2.reset_index(drop=True)\n",
    "\n",
    "# create the table of samples which are not-similar \n",
    "tdf = pd.concat([tdf1, tdf2], axis = 1)\n",
    "tdf.insert(2, 'Relationship', 'None')\n",
    "tdf = tdf.drop_duplicates(subset=['CourseCode1', 'CourseCode2'], keep='first')\n",
    "tdf = tdf.query(\"CourseCode1 != CourseCode2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge the similar and not-similar samples into a single table \n",
    "cddf = pd.concat([cddf, tdf], axis=0, sort=False)\n",
    "cddf = cddf.reset_index(drop=True)\n",
    "\n",
    "# remove duplicates\n",
    "# (since the sampling is random, it could happen that a pair of courses is both similar and not-similar\n",
    "# we keep just the similar version of these pairs, since that is the ground truth)\n",
    "cddf = cddf.drop_duplicates(subset=['CourseCode1', 'CourseCode2'], keep='first')\n",
    "\n",
    "# shuffle\n",
    "cddf = cddf.sample(frac = 1)\n",
    "cddf = cddf.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have one dataframe for all course-pairs (both similar and not-similar) we will perform pre-processing on it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['CourseContent1', 'CourseName1', 'CourseContent2', 'CourseName2', 'TagValue1', 'TagValue2']\n",
    "\n",
    "for column in columns:\n",
    "    # tokenization\n",
    "    apply_preproc(cddf, column, word_tokenize)\n",
    "    # to lower\n",
    "    apply_preproc(cddf, column, to_lower)\n",
    "    # remove stop words\n",
    "    apply_preproc(cddf, column, remove_stop_words)\n",
    "    # remove french stop words\n",
    "    apply_preproc(cddf, column, remove_french_stop_words)\n",
    "    # remove punc\n",
    "    apply_preproc(cddf, column, remove_punc)\n",
    "\n",
    "# remove most common words\n",
    "# ONLY for the course content\n",
    "apply_preproc(cddf, 'CourseContent1', remove_most_common_words)\n",
    "apply_preproc(cddf, 'CourseContent2', remove_most_common_words)\n",
    "\n",
    "# merge content and keywords\n",
    "cddf['CourseContent1'] = cddf['TagValue1'] + cddf['CourseContent1']\n",
    "cddf['CourseContent2'] = cddf['TagValue2'] + cddf['CourseContent2']\n",
    "cddf = cddf.drop(columns=['TagValue1', 'TagValue2'])\n",
    "\n",
    "# merge name and content\n",
    "cddf['CourseContent1'] = cddf['CourseName1'] + cddf['CourseContent1']\n",
    "cddf['CourseContent2'] = cddf['CourseName2'] + cddf['CourseContent2']\n",
    "cddf = cddf.drop(columns=['CourseName1', 'CourseName2'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check out how our pre-processed dataframe looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CourseCode2</th>\n",
       "      <th>CourseCode1</th>\n",
       "      <th>CourseContent1</th>\n",
       "      <th>Relationship</th>\n",
       "      <th>CourseContent2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CS-323</td>\n",
       "      <td>CS-323(a)</td>\n",
       "      <td>[operating, systems, implementation, linux, op...</td>\n",
       "      <td>Depends on</td>\n",
       "      <td>[introduction, operating, systems, operating, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CS-486</td>\n",
       "      <td>COM-480</td>\n",
       "      <td>[data, visualization, data, science, data, viz...</td>\n",
       "      <td>Benefits from</td>\n",
       "      <td>[human, computer, interaction, user, experienc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MATH-106(e)</td>\n",
       "      <td>DH-403</td>\n",
       "      <td>[measuring, literature, distant, reading, digi...</td>\n",
       "      <td>None</td>\n",
       "      <td>[analysis, ii, lagrange, multipliers, differen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CH-313</td>\n",
       "      <td>CH-411</td>\n",
       "      <td>[cellular, signalling, protein, modifications,...</td>\n",
       "      <td>Benefits from</td>\n",
       "      <td>[biochemistry, ii, cofacteur, metabolism, cata...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ME-232</td>\n",
       "      <td>FIN-404</td>\n",
       "      <td>[derivatives, derivatives, évaluation, arbitra...</td>\n",
       "      <td>None</td>\n",
       "      <td>[mechanics, structures, gm, structures, equili...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>CS-473</td>\n",
       "      <td>CS-309</td>\n",
       "      <td>[projet, systems-on-chip, oscilloscope, embedd...</td>\n",
       "      <td>Prepares for</td>\n",
       "      <td>[embedded, systems, embedded, systems, microco...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>PHYS-106(h)</td>\n",
       "      <td>MGT-408</td>\n",
       "      <td>[technology, policy, energy, transition, marke...</td>\n",
       "      <td>None</td>\n",
       "      <td>[general, physics, ii, rigid, body, équation, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ENG-445</td>\n",
       "      <td>MICRO-270</td>\n",
       "      <td>[chemistry, surfaces, caractérisation, surface...</td>\n",
       "      <td>None</td>\n",
       "      <td>[building, energetics, energy, flows, building...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>HUM-216</td>\n",
       "      <td>CIVIL-443</td>\n",
       "      <td>[advanced, composites, engineering, structures...</td>\n",
       "      <td>None</td>\n",
       "      <td>[philosophy, science, creationism, natural, se...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>PHYS-312</td>\n",
       "      <td>PHYS-311</td>\n",
       "      <td>[nuclear, particle, physics, physique, hautes,...</td>\n",
       "      <td>Prepares for</td>\n",
       "      <td>[nuclear, particle, physics, ii, nuclear, phys...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CourseCode2 CourseCode1                                     CourseContent1  \\\n",
       "0       CS-323   CS-323(a)  [operating, systems, implementation, linux, op...   \n",
       "1       CS-486     COM-480  [data, visualization, data, science, data, viz...   \n",
       "2  MATH-106(e)      DH-403  [measuring, literature, distant, reading, digi...   \n",
       "3       CH-313      CH-411  [cellular, signalling, protein, modifications,...   \n",
       "4       ME-232     FIN-404  [derivatives, derivatives, évaluation, arbitra...   \n",
       "5       CS-473      CS-309  [projet, systems-on-chip, oscilloscope, embedd...   \n",
       "6  PHYS-106(h)     MGT-408  [technology, policy, energy, transition, marke...   \n",
       "7      ENG-445   MICRO-270  [chemistry, surfaces, caractérisation, surface...   \n",
       "8      HUM-216   CIVIL-443  [advanced, composites, engineering, structures...   \n",
       "9     PHYS-312    PHYS-311  [nuclear, particle, physics, physique, hautes,...   \n",
       "\n",
       "    Relationship                                     CourseContent2  \n",
       "0     Depends on  [introduction, operating, systems, operating, ...  \n",
       "1  Benefits from  [human, computer, interaction, user, experienc...  \n",
       "2           None  [analysis, ii, lagrange, multipliers, differen...  \n",
       "3  Benefits from  [biochemistry, ii, cofacteur, metabolism, cata...  \n",
       "4           None  [mechanics, structures, gm, structures, equili...  \n",
       "5   Prepares for  [embedded, systems, embedded, systems, microco...  \n",
       "6           None  [general, physics, ii, rigid, body, équation, ...  \n",
       "7           None  [building, energetics, energy, flows, building...  \n",
       "8           None  [philosophy, science, creationism, natural, se...  \n",
       "9   Prepares for  [nuclear, particle, physics, ii, nuclear, phys...  "
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cddf.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:anaconda3]",
   "language": "python",
   "name": "conda-env-anaconda3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
